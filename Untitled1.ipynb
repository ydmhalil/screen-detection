{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be75a462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Detailed report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tabs_report.csv.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pytesseract import pytesseract, Output\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def advanced_tabs_detection_mark_all(video_path, keywords, output_csv, output_folder, sample_rate=5):\n",
    "    \"\"\"\n",
    "    Detects all instances of warning words in browser tabs and generates a detailed report.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        sample_rate (int): Time interval (in seconds) to sample frames.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_rate = int(fps * sample_rate)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    report_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % frame_rate == 0:\n",
    "            timestamp = frame_count / fps\n",
    "\n",
    "            # Focus on the region where browser tabs appear\n",
    "            height, width = frame.shape[:2]\n",
    "            tabs_roi = frame[0:int(height * 0.08), :]  # Crop the top 8% of the screen\n",
    "\n",
    "            # Resize the cropped region for better OCR detection\n",
    "            resized_tabs_roi = cv2.resize(tabs_roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Convert ROI to grayscale\n",
    "            gray_tabs = cv2.cvtColor(resized_tabs_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply CLAHE for contrast enhancement\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            enhanced_tabs = clahe.apply(gray_tabs)\n",
    "\n",
    "            # Perform OCR on the enhanced tabs region\n",
    "            ocr_result = pytesseract.image_to_data(\n",
    "                enhanced_tabs,\n",
    "                output_type=Output.DICT,\n",
    "                config=\"--psm 11 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\",\n",
    "            )\n",
    "\n",
    "            found_keywords = []\n",
    "            file_name = None\n",
    "\n",
    "            # Iterate over detected words\n",
    "            for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                word = word.strip()\n",
    "                if word in keywords:\n",
    "                    found_keywords.append(word)\n",
    "                    x, y, w, h = (\n",
    "                        ocr_result[\"left\"][i],\n",
    "                        ocr_result[\"top\"][i],\n",
    "                        ocr_result[\"width\"][i],\n",
    "                        ocr_result[\"height\"][i],\n",
    "                    )\n",
    "                    # Draw rectangle around each detected keyword\n",
    "                    cv2.rectangle(resized_tabs_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(resized_tabs_roi, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            if found_keywords:\n",
    "                # Save the annotated frame\n",
    "                file_name = f\"frame_tabs_{frame_count}.png\"\n",
    "                output_frame_path = os.path.join(output_folder, file_name)\n",
    "                cv2.imwrite(output_frame_path, resized_tabs_roi)\n",
    "\n",
    "            # Append report data\n",
    "            report_data.append({\n",
    "                \"Exact Time (s)\": round(timestamp, 2),\n",
    "                \"File Name\": file_name if found_keywords else \"None\",\n",
    "                \"Detected Keywords\": \", \".join(found_keywords) if found_keywords else \"None\",\n",
    "                \"Warning\": 1 if found_keywords else 0\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Detailed report saved to {output_csv}.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_3.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\",\"chatgpt\"]\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tabs_report.csv\"\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tabs_mark_all_frames\"\n",
    "    sample_rate = 5  # Sample every 5 seconds\n",
    "\n",
    "    advanced_tabs_detection_mark_all(video_path, keywords, output_csv, output_folder, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b80d3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting easyocr\n",
      "  Obtaining dependency information for easyocr from https://files.pythonhosted.org/packages/bb/84/4a2cab0e6adde6a85e7ba543862e5fc0250c51f3ac721a078a55cdcff250/easyocr-1.7.2-py3-none-any.whl.metadata\n",
      "  Using cached easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting torch (from easyocr)\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/0d/4a/e51420d46cfc90562e85af2fee912237c662ab31140ab179e49bd69401d6/torch-2.5.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.5.1-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision>=0.5 (from easyocr)\n",
      "  Obtaining dependency information for torchvision>=0.5 from https://files.pythonhosted.org/packages/69/55/ce836703ff77bb21582c3098d5311f8ddde7eadc7eab04be9561961f4725/torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.20.1-cp311-cp311-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting opencv-python-headless (from easyocr)\n",
      "  Obtaining dependency information for opencv-python-headless from https://files.pythonhosted.org/packages/26/d0/22f68eb23eea053a31655960f133c0be9726c6a881547e6e9e7e2a946c4f/opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (1.11.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (1.26.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (10.0.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (0.20.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (0.6.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (6.0)\n",
      "Requirement already satisfied: Shapely in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (2.0.6)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\halil\\anaconda3\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Collecting ninja (from easyocr)\n",
      "  Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/72/97/4109961b899ff2decfc0439de442cbe846c94210f263260a211cbee2b29d/ninja-1.11.1.2-py3-none-win_amd64.whl.metadata\n",
      "  Using cached ninja-1.11.1.2-py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (2023.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from torch->easyocr) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2.26.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (23.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from scikit-image->easyocr) (0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\halil\\anaconda3\\lib\\site-packages (from jinja2->torch->easyocr) (2.1.1)\n",
      "Using cached easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
      "Using cached torchvision-0.20.1-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "Using cached torch-2.5.1-cp311-cp311-win_amd64.whl (203.1 MB)\n",
      "Using cached ninja-1.11.1.2-py3-none-win_amd64.whl (296 kB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "Installing collected packages: opencv-python-headless, ninja, torch, torchvision, easyocr\n",
      "Successfully installed easyocr-1.7.2 ninja-1.11.1.2 opencv-python-headless-4.10.0.84 torch-2.5.1 torchvision-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe, torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\Halil\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script easyocr.exe is installed in 'C:\\Users\\Halil\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install easyocr --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "034a5eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_enhanced_report.csv.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pytesseract import pytesseract, Output\n",
    "import pandas as pd\n",
    "# EasyOCR yüklemek için: pip install easyocr\n",
    "# EasyOCR'yi kullanmak istiyorsanız aşağıdaki yorum satırını açın:\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_keywords_with_improvements(video_path, keywords, output_csv, output_folder, sample_rate=5, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects warning words in an expanded browser area (including URL) with advanced preprocessing and optional EasyOCR.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        sample_rate (int): Time interval (in seconds) to sample frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    # EasyOCR Reader (initialize if selected)\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_rate = int(fps * sample_rate)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    report_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % frame_rate == 0:\n",
    "            timestamp = frame_count / fps\n",
    "\n",
    "            # Expanded ROI to include more of the browser area (e.g., top 40%)\n",
    "            height, width = frame.shape[:2]\n",
    "            expanded_roi = frame[0:int(height * 0.40), :]  # Crop the top 40% of the screen\n",
    "\n",
    "            # Resize the cropped region for better OCR detection\n",
    "            resized_roi = cv2.resize(expanded_roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Convert ROI to grayscale\n",
    "            gray_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply GaussianBlur for noise reduction\n",
    "            blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "\n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                blurred_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            found_keywords = set()\n",
    "            file_name = None\n",
    "\n",
    "            if use_easyocr:\n",
    "                # EasyOCR Detection\n",
    "                results = reader.readtext(adaptive_thresh)\n",
    "                for bbox, word, confidence in results:\n",
    "                    if any(keyword in word for keyword in keywords):\n",
    "                        found_keywords.add(word)\n",
    "                        (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                        cv2.rectangle(resized_roi, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_roi, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Tesseract OCR Detection\n",
    "                ocr_result = pytesseract.image_to_data(\n",
    "                    adaptive_thresh,\n",
    "                    output_type=Output.DICT,\n",
    "                    config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "                )\n",
    "\n",
    "                for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                    word = word.strip()\n",
    "                    if word in keywords:\n",
    "                        found_keywords.add(word)\n",
    "                        x, y, w, h = (\n",
    "                            ocr_result[\"left\"][i],\n",
    "                            ocr_result[\"top\"][i],\n",
    "                            ocr_result[\"width\"][i],\n",
    "                            ocr_result[\"height\"][i],\n",
    "                        )\n",
    "                        cv2.rectangle(resized_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_roi, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            if found_keywords:\n",
    "                # Save the annotated frame\n",
    "                file_name = f\"frame_tabs_url_{frame_count}.png\"\n",
    "                output_frame_path = os.path.join(output_folder, file_name)\n",
    "                cv2.imwrite(output_frame_path, resized_roi)\n",
    "\n",
    "            # Append report data\n",
    "            report_data.append({\n",
    "                \"Exact Time (s)\": round(timestamp, 2),\n",
    "                \"File Name\": file_name if found_keywords else \"None\",\n",
    "                \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "                \"Warning\": 1 if found_keywords else 0\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\"]\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_enhanced_report.csv\"\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_enhanced_frames\"\n",
    "    sample_rate = 5  # Sample every 5 seconds\n",
    "\n",
    "    # Set use_easyocr=True to use EasyOCR instead of Tesseract\n",
    "    detect_keywords_with_improvements(video_path, keywords, output_csv, output_folder, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda2fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "037d6422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_full_report.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pytesseract import pytesseract, Output\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_keywords_in_all_frames(video_path, keywords, output_csv, output_folder, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects warning words in all frames of the video to avoid missing keywords.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    # Initialize EasyOCR Reader if selected\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    report_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        timestamp = frame_count / fps\n",
    "\n",
    "        # Expanded ROI to include browser area\n",
    "        height, width = frame.shape[:2]\n",
    "        expanded_roi = frame[0:int(height * 0.40), :]  # Crop the top 40% of the screen\n",
    "\n",
    "        # Resize the cropped region for better OCR detection\n",
    "        resized_roi = cv2.resize(expanded_roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # Convert ROI to grayscale\n",
    "        gray_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply GaussianBlur for noise reduction\n",
    "        blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "\n",
    "        # Apply adaptive thresholding\n",
    "        adaptive_thresh = cv2.adaptiveThreshold(\n",
    "            blurred_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "        )\n",
    "\n",
    "        found_keywords = set()\n",
    "        file_name = None\n",
    "\n",
    "        if use_easyocr:\n",
    "            results = reader.readtext(adaptive_thresh)\n",
    "            for bbox, word, confidence in results:\n",
    "                if any(keyword in word for keyword in keywords):\n",
    "                    found_keywords.add(word)\n",
    "                    (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                    cv2.rectangle(resized_roi, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                    cv2.putText(resized_roi, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        else:\n",
    "            ocr_result = pytesseract.image_to_data(\n",
    "                adaptive_thresh,\n",
    "                output_type=Output.DICT,\n",
    "                config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "            )\n",
    "            for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                word = word.strip()\n",
    "                if word in keywords:\n",
    "                    found_keywords.add(word)\n",
    "                    x, y, w, h = (\n",
    "                        ocr_result[\"left\"][i],\n",
    "                        ocr_result[\"top\"][i],\n",
    "                        ocr_result[\"width\"][i],\n",
    "                        ocr_result[\"height\"][i],\n",
    "                    )\n",
    "                    cv2.rectangle(resized_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                    cv2.putText(resized_roi, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        if found_keywords:\n",
    "            # Save the annotated frame\n",
    "            file_name = f\"frame_tabs_url_{frame_count}.png\"\n",
    "            output_frame_path = os.path.join(output_folder, file_name)\n",
    "            cv2.imwrite(output_frame_path, resized_roi)\n",
    "\n",
    "        # Append report data\n",
    "        report_data.append({\n",
    "            \"Exact Time (s)\": round(timestamp, 2),\n",
    "            \"File Name\": file_name if found_keywords else \"None\",\n",
    "            \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "            \"Warning\": 1 if found_keywords else 0\n",
    "        })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your file paths\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Input video file path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\", \"blackbox.ai\",\"blackbox\",\"ai\",\"Blackbox\",\"Aı\",\"AI\",\"perplexity.ai\",\"perplexity\",\n",
    "           \"github\",\"stackoverflow\"]  # Keywords to search\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_full_report.csv\"  # CSV output path\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_annotated_frames\"  # Folder for annotated frames\n",
    "\n",
    "    detect_keywords_in_all_frames(video_path, keywords, output_csv, output_folder, use_easyocr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hareket analizi ile görsel yakalama programın çalışma hızını arttırabilir.\n",
    "\n",
    "#Program haline yani MLOPS haline getirebilmeliyiz.\n",
    "\n",
    "#Resim piksel analizi yapmaya gerek kalmayabilir. Text analiz şuanlık yeterli bir çözüm olarak görünüyor.\n",
    "\n",
    "#Keywords kısmını genişletmeliyiz.\n",
    "\n",
    "#Raporlama kısmı şuanlık çok basit, daha gelişmiş daha anlaşılır ve daha kullanışlı olmalı. Tıpkı bir program gibi.\n",
    "\n",
    "#Sadece tek bir videoya değil tüm kayıtları kontrol etmeli, her kayıt farklı birer kullanıcıya ait dolayısıyla kullanıcı \n",
    "#bazlı bir raporlama yapmalıyız. As kullanıcı (Üniversite, akademisyen vs.) kimlerin uyarılı bir davranış yaptığını kolaylıkla\n",
    "#erişebilmelidir.\n",
    "\n",
    "#Tüm sayfa üzerinden arama yapalım, çünkü bazı eklentiler üst kısımda görünmeyebilir.\n",
    "\n",
    "keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\", \"blackbox.ai\",\"blackbox\",\"ai\",\"Blackbox\",\"Aı\",\"AI\",\"perplexity.ai\",\"perplexity\",\n",
    "           \"github\",\"stackoverflow\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1797c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_motion_report.csv.\n"
     ]
    }
   ],
   "source": [
    "##Güncellenmiş Kod: Hareket Algılamalı OCR##\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytesseract import pytesseract, Output\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_keywords_with_motion_detection(video_path, keywords, output_csv, output_folder, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects warning words in frames where motion is detected to optimize OCR processing.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Background subtractor for motion detection\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    report_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        timestamp = frame_count / fps\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = back_sub.apply(frame)\n",
    "\n",
    "        # Check if motion is detected\n",
    "        if cv2.countNonZero(fg_mask) > 5000:  # Motion threshold\n",
    "            # Expanded ROI to include more of the browser area\n",
    "            height, width = frame.shape[:2]\n",
    "            expanded_roi = frame[0:int(height * 0.40), :]  # Crop the top 40% of the screen\n",
    "\n",
    "            # Resize the cropped region for better OCR detection\n",
    "            resized_roi = cv2.resize(expanded_roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Convert ROI to grayscale\n",
    "            gray_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply GaussianBlur for noise reduction\n",
    "            blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "\n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                blurred_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            found_keywords = set()\n",
    "            file_name = None\n",
    "\n",
    "            if use_easyocr:\n",
    "                results = reader.readtext(adaptive_thresh)\n",
    "                for bbox, word, confidence in results:\n",
    "                    if any(keyword in word for keyword in keywords):\n",
    "                        found_keywords.add(word)\n",
    "                        (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                        cv2.rectangle(resized_roi, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_roi, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                ocr_result = pytesseract.image_to_data(\n",
    "                    adaptive_thresh,\n",
    "                    output_type=Output.DICT,\n",
    "                    config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "                )\n",
    "                for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                    word = word.strip()\n",
    "                    if word in keywords:\n",
    "                        found_keywords.add(word)\n",
    "                        x, y, w, h = (\n",
    "                            ocr_result[\"left\"][i],\n",
    "                            ocr_result[\"top\"][i],\n",
    "                            ocr_result[\"width\"][i],\n",
    "                            ocr_result[\"height\"][i],\n",
    "                        )\n",
    "                        cv2.rectangle(resized_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_roi, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            if found_keywords:\n",
    "                # Save the annotated frame\n",
    "                file_name = f\"frame_tabs_url_{frame_count}.png\"\n",
    "                output_frame_path = os.path.join(output_folder, file_name)\n",
    "                cv2.imwrite(output_frame_path, resized_roi)\n",
    "\n",
    "            # Append report data\n",
    "            report_data.append({\n",
    "                \"Exact Time (s)\": round(timestamp, 2),\n",
    "                \"File Name\": file_name if found_keywords else \"None\",\n",
    "                \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "                \"Warning\": 1 if found_keywords else 0\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\", \"blackbox.ai\",\"blackbox\",\"Blackbox\",\"perplexity.ai\",\"perplexity\",\n",
    "           \"github\",\"stackoverflow\"]  # Keywords to search\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_motion_report.csv\"  # CSV output path\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_motion_frames\"  # Folder for annotated frames\n",
    "\n",
    "    detect_keywords_with_motion_detection(video_path, keywords, output_csv, output_folder, use_easyocr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9c68fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tab_change_report.csv.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytesseract import pytesseract, Output\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_tab_changes_and_keywords(video_path, keywords, output_csv, output_folder, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects tab changes in the video and performs OCR only when tab changes are detected.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Background subtractor for motion detection\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    report_data = []\n",
    "    prev_fg_mask = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        timestamp = frame_count / fps\n",
    "\n",
    "        # Focus on the tab region (e.g., top 15% of the screen)\n",
    "        height, width = frame.shape[:2]\n",
    "        tabs_roi = frame[0:int(height * 0.15), :]  # Crop the top 15% of the screen\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = back_sub.apply(tabs_roi)\n",
    "\n",
    "        # Compare current and previous foreground masks\n",
    "        if prev_fg_mask is not None:\n",
    "            diff = cv2.absdiff(fg_mask, prev_fg_mask)\n",
    "            motion_score = cv2.countNonZero(diff)\n",
    "\n",
    "            # Check if significant motion (tab change) is detected\n",
    "            if motion_score > 1000:  # Motion threshold\n",
    "                resized_roi = cv2.resize(tabs_roi, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "                gray_roi = cv2.cvtColor(resized_roi, cv2.COLOR_BGR2GRAY)\n",
    "                blurred_roi = cv2.GaussianBlur(gray_roi, (5, 5), 0)\n",
    "                adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                    blurred_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "                )\n",
    "\n",
    "                found_keywords = set()\n",
    "                file_name = None\n",
    "\n",
    "                if use_easyocr:\n",
    "                    results = reader.readtext(adaptive_thresh)\n",
    "                    for bbox, word, confidence in results:\n",
    "                        if any(keyword in word for keyword in keywords):\n",
    "                            found_keywords.add(word)\n",
    "                            (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                            cv2.rectangle(resized_roi, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                            cv2.putText(resized_roi, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    ocr_result = pytesseract.image_to_data(\n",
    "                        adaptive_thresh,\n",
    "                        output_type=Output.DICT,\n",
    "                        config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "                    )\n",
    "                    for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                        word = word.strip()\n",
    "                        if word in keywords:\n",
    "                            found_keywords.add(word)\n",
    "                            x, y, w, h = (\n",
    "                                ocr_result[\"left\"][i],\n",
    "                                ocr_result[\"top\"][i],\n",
    "                                ocr_result[\"width\"][i],\n",
    "                                ocr_result[\"height\"][i],\n",
    "                            )\n",
    "                            cv2.rectangle(resized_roi, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                            cv2.putText(resized_roi, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                if found_keywords:\n",
    "                    # Save the annotated frame\n",
    "                    file_name = f\"frame_tab_change_{frame_count}.png\"\n",
    "                    output_frame_path = os.path.join(output_folder, file_name)\n",
    "                    cv2.imwrite(output_frame_path, resized_roi)\n",
    "\n",
    "                # Append report data\n",
    "                report_data.append({\n",
    "                    \"Exact Time (s)\": round(timestamp, 2),\n",
    "                    \"File Name\": file_name if found_keywords else \"None\",\n",
    "                    \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "                    \"Warning\": 1 if found_keywords else 0\n",
    "                })\n",
    "\n",
    "        prev_fg_mask = fg_mask\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\"]  # Keywords to search\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tab_change_report.csv\"  # CSV output path\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_tab_change_frames\"  # Folder for annotated frames\n",
    "\n",
    "    detect_tab_changes_and_keywords(video_path, keywords, output_csv, output_folder, use_easyocr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af97b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ff890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "326a4cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection complete. Report saved to C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_full_page_report.csv.\n"
     ]
    }
   ],
   "source": [
    "#TAM SAYFA ANALİZ - HER 5 SN'DE 1\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytesseract import pytesseract, Output\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_keywords_full_page(video_path, keywords, output_csv, output_folder, sample_rate=5, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects warning words in the entire page of the video frames.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        sample_rate (int): Time interval (in seconds) to sample frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_rate = int(fps * sample_rate)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    report_data = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        if frame_count % frame_rate == 0:\n",
    "            timestamp = frame_count / fps\n",
    "\n",
    "            # Resize the entire frame for better OCR detection\n",
    "            resized_frame = cv2.resize(frame, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Convert the frame to grayscale\n",
    "            gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Apply GaussianBlur for noise reduction\n",
    "            blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "\n",
    "            # Apply adaptive thresholding\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                blurred_frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            found_keywords = set()\n",
    "            file_name = None\n",
    "\n",
    "            if use_easyocr:\n",
    "                # EasyOCR detection\n",
    "                results = reader.readtext(adaptive_thresh)\n",
    "                for bbox, word, confidence in results:\n",
    "                    if any(keyword in word for keyword in keywords):\n",
    "                        found_keywords.add(word)\n",
    "                        (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                        cv2.rectangle(resized_frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_frame, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Tesseract OCR detection\n",
    "                ocr_result = pytesseract.image_to_data(\n",
    "                    adaptive_thresh,\n",
    "                    output_type=Output.DICT,\n",
    "                    config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "                )\n",
    "                for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                    word = word.strip()\n",
    "                    if word in keywords:\n",
    "                        found_keywords.add(word)\n",
    "                        x, y, w, h = (\n",
    "                            ocr_result[\"left\"][i],\n",
    "                            ocr_result[\"top\"][i],\n",
    "                            ocr_result[\"width\"][i],\n",
    "                            ocr_result[\"height\"][i],\n",
    "                        )\n",
    "                        cv2.rectangle(resized_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_frame, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            if found_keywords:\n",
    "                # Save the annotated frame\n",
    "                file_name = f\"frame_full_page_{frame_count}.png\"\n",
    "                output_frame_path = os.path.join(output_folder, file_name)\n",
    "                cv2.imwrite(output_frame_path, resized_frame)\n",
    "\n",
    "            # Append report data\n",
    "            report_data.append({\n",
    "                \"Exact Time (s)\": round(timestamp, 2),\n",
    "                \"File Name\": file_name if found_keywords else \"None\",\n",
    "                \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "                \"Warning\": 1 if found_keywords else 0\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\", \"blackbox.ai\",\"blackbox\",\"Blackbox\",\"perplexity.ai\",\"perplexity\",\n",
    "           \"github\",\"stackoverflow\"]  # Keywords to search\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_full_page_report.csv\"  # CSV output path\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_full_page_frames\"  # Folder for annotated frames\n",
    "\n",
    "    detect_keywords_full_page(video_path, keywords, output_csv, output_folder, sample_rate=5, use_easyocr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095753c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1231e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "#Hareket Algılamalı & Tüm Ekran\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from pytesseract import pytesseract, Output\n",
    "import easyocr\n",
    "\n",
    "# Ensure pytesseract path is set\n",
    "pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "def detect_keywords_with_motion(video_path, keywords, output_csv, output_folder, use_easyocr=True):\n",
    "    \"\"\"\n",
    "    Detects warning words based on motion detection in the video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video file.\n",
    "        keywords (list): List of warning words to detect.\n",
    "        output_csv (str): Path to save the detection report as a CSV file.\n",
    "        output_folder (str): Folder to save annotated frames.\n",
    "        use_easyocr (bool): Whether to use EasyOCR instead of Tesseract.\n",
    "    \"\"\"\n",
    "    if use_easyocr:\n",
    "        reader = easyocr.Reader(['en'])\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Background subtractor for motion detection\n",
    "    back_sub = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    report_data = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        timestamp = frame_count / fps\n",
    "\n",
    "        # Apply background subtraction to detect motion\n",
    "        fg_mask = back_sub.apply(frame)\n",
    "        motion_score = cv2.countNonZero(fg_mask)\n",
    "\n",
    "        # Motion threshold to trigger OCR\n",
    "        if motion_score > 5000:  # Adjust threshold based on your video\n",
    "            resized_frame = cv2.resize(frame, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "            gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "            blurred_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "            adaptive_thresh = cv2.adaptiveThreshold(\n",
    "                blurred_frame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2\n",
    "            )\n",
    "\n",
    "            found_keywords = set()\n",
    "            file_name = None\n",
    "\n",
    "            if use_easyocr:\n",
    "                results = reader.readtext(adaptive_thresh)\n",
    "                for bbox, word, confidence in results:\n",
    "                    if any(keyword in word for keyword in keywords):\n",
    "                        found_keywords.add(word)\n",
    "                        (x_min, y_min), (x_max, y_max) = bbox[0], bbox[2]\n",
    "                        cv2.rectangle(resized_frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_frame, word, (int(x_min), int(y_min) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                ocr_result = pytesseract.image_to_data(\n",
    "                    adaptive_thresh,\n",
    "                    output_type=Output.DICT,\n",
    "                    config=\"--psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789:/.-\",\n",
    "                )\n",
    "                for i, word in enumerate(ocr_result[\"text\"]):\n",
    "                    word = word.strip()\n",
    "                    if word in keywords:\n",
    "                        found_keywords.add(word)\n",
    "                        x, y, w, h = (\n",
    "                            ocr_result[\"left\"][i],\n",
    "                            ocr_result[\"top\"][i],\n",
    "                            ocr_result[\"width\"][i],\n",
    "                            ocr_result[\"height\"][i],\n",
    "                        )\n",
    "                        cv2.rectangle(resized_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        cv2.putText(resized_frame, word, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            if found_keywords:\n",
    "                file_name = f\"frame_motion_{frame_count}.png\"\n",
    "                output_frame_path = os.path.join(output_folder, file_name)\n",
    "                cv2.imwrite(output_frame_path, resized_frame)\n",
    "\n",
    "            # Append report data\n",
    "            report_data.append({\n",
    "                \"Exact Time (s)\": round(timestamp, 2),\n",
    "                \"File Name\": file_name if found_keywords else \"None\",\n",
    "                \"Detected Keywords\": \", \".join(sorted(found_keywords)) if found_keywords else \"None\",\n",
    "                \"Warning\": 1 if found_keywords else 0\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Save results to CSV\n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    report_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Detection complete. Report saved to {output_csv}.\")\n",
    "\n",
    "# Script entry point\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\datasets\\sample_2.mp4\"  # Replace with your video path\n",
    "    keywords = [\"gpt\", \"GPT\", \"ChatGPT\", \"chatgpt\", \"blackbox.ai\",\"blackbox\",\"Blackbox\",\"perplexity.ai\",\"perplexity\",\n",
    "           \"github\",\"stackoverflow\"]  # Keywords to search\n",
    "    output_csv = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_motion_based_report.csv\"  # CSV output path\n",
    "    output_folder = r\"C:\\Users\\Halil\\PycharmProjects\\Untitled Folder\\output_motion_based_frames\"  # Folder for annotated frames\n",
    "\n",
    "    detect_keywords_with_motion(video_path, keywords, output_csv, output_folder, use_easyocr=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2997093c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
